{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c56e68a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6a81e5",
   "metadata": {},
   "source": [
    "#### some theory \n",
    "- At the heart of the Naive Bayes classifier is Bayes' theorem, a fundamental concept\n",
    "in probability theory\n",
    "\n",
    "- There are different variants of Naive Bayes classifiers,\n",
    "including Multinomial and Gaussian Naive Bayes. Multinomial Naive Bayes is commonly used for\n",
    "text data, while Gaussian Naive Bayes is suitable for continuous data with a normal distribution.\n",
    "\n",
    "- Step 1: Install scikit-learn\n",
    "If you haven't already installed scikit-learn, you can do so using pip:\n",
    "!pip install scikit-learn\n",
    "\n",
    "Step 2: Import Necessary Libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Step 3: Prepare Your Data\n",
    "Assuming you have a dataset with text samples and corresponding labels (e.g., positive or negative sentiment),\n",
    "you should split the data into a training set and a test set. Here's an example:\n",
    "# Sample data\n",
    "texts = [\"This is a positive review.\", \"Negative sentiment detected.\", \"A very positive experience.\", \"I didn't\n",
    "like this at all.\"]\n",
    "# Corresponding labels (1 for positive, 0 for negative)\n",
    "labels = [1, 0, 1, 0]\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "         \n",
    "Step 4: Feature Extraction\n",
    "You need to convert the text data into numerical features. One common approach is to use the\n",
    "CountVectorizer, which counts the frequency of words in the text. Here's how to do it:\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "         \n",
    "Step 5: Train the Naïve Bayes Classifier\n",
    "Next, create and train the Naïve Bayes classifier. For text classification, the Multinomial Naïve Bayes\n",
    "classifier is commonly used:\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_vec, y_train)\n",
    "         \n",
    "Step 6: Make Predictions\n",
    "Once the classifier is trained, you can use it to make predictions on new data:\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "         \n",
    "Step 7: Evaluate the Model\n",
    "Evaluate the model's performance using appropriate metrics:\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred) print(f\"Accuracy: {accuracy}\") print(report)\n",
    "         \n",
    "This code demonstrates a basic implementation of the Naïve Bayes Classifier in Python using scikit-learn.\n",
    "Depending on your specific task and dataset, you may need to fine-tune the pre-processing steps, hyper\n",
    "parameters, and model selection to achieve the best performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c4d66d",
   "metadata": {},
   "source": [
    "### q1 \n",
    "1. Implement in python program of the following problems using Bayes Theorem.\n",
    "\n",
    "a) Of the students in the college, 60% of the students reside in the hostel and 40% of the students are day\n",
    "scholars. Previous year results report that 30% of all students who stay in the hostel scored A Grade and 20%\n",
    "of day scholars scored A grade. At the end of the year, one student is chosen at random and found that he/she\n",
    "has an A grade. What is the probability that the student is a hosteler?\n",
    "\n",
    "b) Suppose you're testing for a rare disease, and you have the following information:\n",
    " The disease has a prevalence of 0.01 (1% of the population has the disease).\n",
    " The test is not perfect:\n",
    " The test correctly identifies the disease (true positive) 99% of the time (sensitivity).\n",
    "\n",
    " The test incorrectly indicates the disease (false positive) 2% of the time (1 - specificity).\n",
    "Calculate the probability of having the disease given a positive test result using Bayes' theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce5e23d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26\n",
      "p_h_given A:  0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "####a\n",
    "p_hostel = 0.6\n",
    "p_daySchol = 0.4\n",
    "p_A_hostel = 0.3\n",
    "p_A_daySchol = 0.2\n",
    "\n",
    "p_A = p_A_hostel*p_hostel + p_A_daySchol*p_daySchol\n",
    "print(p_A)\n",
    "\n",
    "P_H_given_A = (p_A_hostel * p_hostel) / p_A\n",
    "print(\"p_h_given A: \", P_H_given_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8889b46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of having the disease given a positive test result: 0.3333\n"
     ]
    }
   ],
   "source": [
    "#### b\n",
    "# Given probabilities\n",
    "P_D = 0.01  # Prevalence of the disease\n",
    "P_T_given_D = 0.99  # Sensitivity (true positive rate)\n",
    "P_T_given_not_D = 0.02  # False positive rate\n",
    "P_not_D = 1 - P_D  # Probability of not having the disease\n",
    "\n",
    "# Total probability of a positive test result\n",
    "P_T = (P_T_given_D * P_D) + (P_T_given_not_D * P_not_D)\n",
    "\n",
    "# Probability of having the disease given a positive test result\n",
    "P_D_given_T = (P_T_given_D * P_D) / P_T\n",
    "\n",
    "print(f\"Probability of having the disease given a positive test result: {P_D_given_T:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708bfc9f",
   "metadata": {},
   "source": [
    "### q2\n",
    "Develop a function python code for Naïve Bayes classifier from scratch without using scikit-learn library,\n",
    "to predict whether the buyer should buy computer or not. Consider a following sample training dataset stored\n",
    "in a CSV file containing information about following buyer conditions (such as “<=30,” “medium,” “Yes,”\n",
    "and “fair”) and whether the player played golf (“Yes” or “No”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8186b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "       age  income student credit_rating buys_computer\n",
      "0    <=30    high      no          fair            no\n",
      "1    <=30    high      no     excellent            no\n",
      "2   31…40    high      no          fair           yes\n",
      "3     >40  medium      no          fair           yes\n",
      "4     >40     low     yes          fair           yes\n",
      "5     >40     low     yes     excellent            no\n",
      "6   31…40     low     yes     excellent           yes\n",
      "7    <=30  medium      no          fair            no\n",
      "8    <=30     low     yes          fair           yes\n",
      "9     >40  medium     yes          fair           yes\n",
      "10   <=30  medium     yes     excellent           yes\n",
      "11  31…40    high     yes          fair           yes\n",
      "12    >40  medium      no     excellent            no\n",
      "\n",
      "Prior Probabilities:\n",
      " {'yes': 0.6153846153846154, 'no': 0.38461538461538464}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the dataset as a dictionary\n",
    "data_dict = {\n",
    "    'age': ['<=30', '<=30', '31…40', '>40', '>40', '>40', '31…40', '<=30', '<=30', '>40', '<=30', '31…40', '>40'],\n",
    "    'income': ['high', 'high', 'high', 'medium', 'low', 'low', 'low', 'medium', 'low', 'medium', 'medium', 'high', 'medium'],\n",
    "    'student': ['no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no'],\n",
    "    'credit_rating': ['fair', 'excellent', 'fair', 'fair', 'fair', 'excellent', 'excellent', 'fair', 'fair', 'fair', 'excellent', 'fair', 'excellent'],\n",
    "    'buys_computer': ['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.to_csv(\"buyDF.csv\")\n",
    "print(\"DataFrame:\\n\", df)\n",
    "\n",
    "# Compute prior probabilities\n",
    "prior_probs = df['buys_computer'].value_counts(normalize=True).to_dict()\n",
    "\n",
    "print(\"\\nPrior Probabilities:\\n\", prior_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cfc3c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<=30': 0.38461538461538464, '>40': 0.38461538461538464, '31…40': 0.23076923076923078}\n"
     ]
    }
   ],
   "source": [
    "p_age = df['age'].value_counts(normalize=True).to_dict()\n",
    "print(p_age)\n",
    "p_age_lessThan30 = (p_age['<=30'])\n",
    "p_age_31to40 = (p_age['31…40'])\n",
    "p_age_moreThan40 = (p_age['>40'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "132c29d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_income = df['income'].value_counts(normalize=True).to_dict()\n",
    "p_income_high = p_income['high']\n",
    "p_income_medium = p_income['medium']\n",
    "p_income_low = p_income['low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1736661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_student = df['student'].value_counts(normalize=True).to_dict()\n",
    "p_student_y = p_student['yes']\n",
    "p_student_n = p_student['no']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d544533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "Class: no\n",
      "class data for  no :       age  income student credit_rating buys_computer\n",
      "0   <=30    high      no          fair            no\n",
      "1   <=30    high      no     excellent            no\n",
      "5    >40     low     yes     excellent            no\n",
      "7   <=30  medium      no          fair            no\n",
      "12   >40  medium      no     excellent            no \n",
      "\n",
      "{'<=30': 0.6, '>40': 0.4}\n",
      "Class: yes\n",
      "class data for  yes :        age  income student credit_rating buys_computer\n",
      "2   31…40    high      no          fair           yes\n",
      "3     >40  medium      no          fair           yes\n",
      "4     >40     low     yes          fair           yes\n",
      "6   31…40     low     yes     excellent           yes\n",
      "8    <=30     low     yes          fair           yes\n",
      "9     >40  medium     yes          fair           yes\n",
      "10   <=30  medium     yes     excellent           yes\n",
      "11  31…40    high     yes          fair           yes \n",
      "\n",
      "{'31…40': 0.375, '>40': 0.375, '<=30': 0.25}\n",
      "income\n",
      "Class: no\n",
      "class data for  no :       age  income student credit_rating buys_computer\n",
      "0   <=30    high      no          fair            no\n",
      "1   <=30    high      no     excellent            no\n",
      "5    >40     low     yes     excellent            no\n",
      "7   <=30  medium      no          fair            no\n",
      "12   >40  medium      no     excellent            no \n",
      "\n",
      "{'high': 0.4, 'medium': 0.4, 'low': 0.2}\n",
      "Class: yes\n",
      "class data for  yes :        age  income student credit_rating buys_computer\n",
      "2   31…40    high      no          fair           yes\n",
      "3     >40  medium      no          fair           yes\n",
      "4     >40     low     yes          fair           yes\n",
      "6   31…40     low     yes     excellent           yes\n",
      "8    <=30     low     yes          fair           yes\n",
      "9     >40  medium     yes          fair           yes\n",
      "10   <=30  medium     yes     excellent           yes\n",
      "11  31…40    high     yes          fair           yes \n",
      "\n",
      "{'medium': 0.375, 'low': 0.375, 'high': 0.25}\n",
      "student\n",
      "Class: no\n",
      "class data for  no :       age  income student credit_rating buys_computer\n",
      "0   <=30    high      no          fair            no\n",
      "1   <=30    high      no     excellent            no\n",
      "5    >40     low     yes     excellent            no\n",
      "7   <=30  medium      no          fair            no\n",
      "12   >40  medium      no     excellent            no \n",
      "\n",
      "{'no': 0.8, 'yes': 0.2}\n",
      "Class: yes\n",
      "class data for  yes :        age  income student credit_rating buys_computer\n",
      "2   31…40    high      no          fair           yes\n",
      "3     >40  medium      no          fair           yes\n",
      "4     >40     low     yes          fair           yes\n",
      "6   31…40     low     yes     excellent           yes\n",
      "8    <=30     low     yes          fair           yes\n",
      "9     >40  medium     yes          fair           yes\n",
      "10   <=30  medium     yes     excellent           yes\n",
      "11  31…40    high     yes          fair           yes \n",
      "\n",
      "{'yes': 0.75, 'no': 0.25}\n",
      "credit_rating\n",
      "Class: no\n",
      "class data for  no :       age  income student credit_rating buys_computer\n",
      "0   <=30    high      no          fair            no\n",
      "1   <=30    high      no     excellent            no\n",
      "5    >40     low     yes     excellent            no\n",
      "7   <=30  medium      no          fair            no\n",
      "12   >40  medium      no     excellent            no \n",
      "\n",
      "{'excellent': 0.6, 'fair': 0.4}\n",
      "Class: yes\n",
      "class data for  yes :        age  income student credit_rating buys_computer\n",
      "2   31…40    high      no          fair           yes\n",
      "3     >40  medium      no          fair           yes\n",
      "4     >40     low     yes          fair           yes\n",
      "6   31…40     low     yes     excellent           yes\n",
      "8    <=30     low     yes          fair           yes\n",
      "9     >40  medium     yes          fair           yes\n",
      "10   <=30  medium     yes     excellent           yes\n",
      "11  31…40    high     yes          fair           yes \n",
      "\n",
      "{'fair': 0.75, 'excellent': 0.25}\n",
      "age : {'no': {'<=30': 0.6, '>40': 0.4}, 'yes': {'31…40': 0.375, '>40': 0.375, '<=30': 0.25}}\n",
      "\n",
      "\n",
      "income : {'no': {'high': 0.4, 'medium': 0.4, 'low': 0.2}, 'yes': {'medium': 0.375, 'low': 0.375, 'high': 0.25}}\n",
      "\n",
      "\n",
      "student : {'no': {'no': 0.8, 'yes': 0.2}, 'yes': {'yes': 0.75, 'no': 0.25}}\n",
      "\n",
      "\n",
      "credit_rating : {'no': {'excellent': 0.6, 'fair': 0.4}, 'yes': {'fair': 0.75, 'excellent': 0.25}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fn to get each features likelihoods given target class\n",
    "def compute_likelihoods(df, feature, target):\n",
    "    likelihoods = {}\n",
    "    target_classes = df[target].unique() #yes / no in our case (buys_comp)\n",
    "    print(feature)\n",
    "    \n",
    "    for cls in target_classes: #ones of yes/no\n",
    "        print(\"Class:\",cls)\n",
    "        cls_data = df[df[target] == cls] ##all data with a given target\n",
    "        print(\"class data for \", cls, \": \",cls_data, '\\n')\n",
    "        feature_counts = cls_data[feature].value_counts(normalize=True).to_dict() # prob of feature=x given target\n",
    "        print(feature_counts)\n",
    "        likelihoods[cls] = feature_counts \n",
    "        #print(likelihoods[cls])\n",
    "        \n",
    "    return likelihoods\n",
    "\n",
    "features = ['age', 'income', 'student', 'credit_rating']\n",
    "likelihoods = {}\n",
    "\n",
    "for feat in features:\n",
    "    likelihoods[feat] = compute_likelihoods(df, feat, 'buys_computer')\n",
    "\n",
    "#BASICALLY : P(FEATURE1=V1 | TARGET = YES/NO)\n",
    "for feat in likelihoods:\n",
    "    print(feat,':', likelihoods[feat], end = '\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ccf3e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_instance(instance, prior_probs, likelihoods):\n",
    "    posteriors = {}\n",
    "    \n",
    "    for cls, prior in prior_probs.items():\n",
    "        posterior = prior\n",
    "        \n",
    "        for feature, value in instance.items():\n",
    "            if feature in likelihoods and cls in likelihoods[feature]:\n",
    "                posterior *= likelihoods[feature][cls].get(value, 1e-6)  # Add small value to avoid zero probabilities\n",
    "        \n",
    "        posteriors[cls] = posterior\n",
    "    \n",
    "    # Normalize to get probabilities\n",
    "    total = sum(posteriors.values())\n",
    "    posteriors = {cls: prob / total for cls, prob in posteriors.items()}\n",
    "    \n",
    "    return posteriors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0dbcf8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior Probabilities for New Instance: {'yes': 0.8146270818247646, 'no': 0.18537291817523538}\n",
      "Predicted Class: yes\n"
     ]
    }
   ],
   "source": [
    "new_instance = {\n",
    "    'age': '<=30',\n",
    "    'income': 'medium',\n",
    "    'student': 'yes',\n",
    "    'credit_rating': 'fair'\n",
    "}\n",
    "\n",
    "posterior_probs = classify_instance(new_instance, prior_probs, likelihoods)\n",
    "print(\"Posterior Probabilities for New Instance:\", posterior_probs)\n",
    "\n",
    "# Predict the class with the highest posterior probability\n",
    "predicted_class = max(posterior_probs, key=posterior_probs.get)\n",
    "print(\"Predicted Class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0431485",
   "metadata": {},
   "source": [
    "### Q3\n",
    "Write a Python function to implement the Naive Bayes classifier without using the scikit-learn library for the\n",
    "following sample training dataset stored as a .CSV file. Calculate the accuracy, precision, and recall for your train/test\n",
    "dataset.\n",
    "\n",
    "a. Build a classifier that determines whether a text is about sports or not.\n",
    "\n",
    "b. Determine which tag the sentence \"A very close game\" belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd613b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Text': [\n",
    "        \"A great game\", \"The election was over\", \"A very close game\",\n",
    "        \"Very clean match\", \"A clean but forgettable game\", \"It was a close election\"\n",
    "    ],\n",
    "    'Tag': ['Sports', 'Not sports', 'Sports', 'Sports', 'Sports', 'Not sports']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Tag'], test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca5f2e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "class NaiveBayesTextClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_priors = {}\n",
    "        self.word_likelihoods = defaultdict(lambda: defaultdict(lambda: 1e-6))  # Smooth with a small value\n",
    "        self.vocab = set()\n",
    "        self.classes = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Compute prior probabilities\n",
    "        total_docs = len(y)\n",
    "        class_counts = y.value_counts()\n",
    "        self.classes = class_counts.index.tolist()\n",
    "        self.class_priors = {cls: count / total_docs for cls, count in class_counts.items()}\n",
    "        \n",
    "        # Count words per class\n",
    "        word_counts = defaultdict(lambda: defaultdict(int))\n",
    "        class_word_counts = defaultdict(int)\n",
    "        \n",
    "        for text, label in zip(X, y):\n",
    "            words = text.lower().split()\n",
    "            self.vocab.update(words)\n",
    "            for word in words:\n",
    "                word_counts[label][word] += 1\n",
    "                class_word_counts[label] += 1\n",
    "        \n",
    "        # Compute likelihoods\n",
    "        for cls in self.classes:\n",
    "            total_words = class_word_counts[cls]\n",
    "            for word in self.vocab:\n",
    "                self.word_likelihoods[cls][word] = (word_counts[cls][word] + 1) / (total_words + len(self.vocab))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for text in X:\n",
    "            words = text.lower().split()\n",
    "            class_probs = {}\n",
    "            \n",
    "            for cls in self.classes:\n",
    "                prob = np.log(self.class_priors[cls])\n",
    "                for word in words:\n",
    "                    prob += np.log(self.word_likelihoods[cls].get(word, 1e-6))\n",
    "                class_probs[cls] = prob\n",
    "            \n",
    "            # Predict the class with the highest probability\n",
    "            predictions.append(max(class_probs, key=class_probs.get))\n",
    "        \n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dad0f02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.33\n",
      "Precision: 0.33\n",
      "Recall: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not sports       0.00      0.00      0.00         2\n",
      "      Sports       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.17      0.50      0.25         3\n",
      "weighted avg       0.11      0.33      0.17         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and train the classifier\n",
    "nb_classifier = NaiveBayesTextClassifier()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label='Sports', average='binary')\n",
    "recall = recall_score(y_test, y_pred, pos_label='Sports', average='binary')\n",
    "report = classification_report(y_test, y_pred, target_names=['Not sports', 'Sports'])\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e683218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence 'A very close game' belongs to the class 'Sports'.\n"
     ]
    }
   ],
   "source": [
    "# Classify a new sentence\n",
    "new_sentence = \"A very close game\"\n",
    "prediction = nb_classifier.predict([new_sentence])[0]\n",
    "print(f\"The sentence '{new_sentence}' belongs to the class '{prediction}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213e7c85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
